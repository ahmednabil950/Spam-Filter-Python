{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Preprocessing import Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read email body only\n",
    "def get_body(mail):\n",
    "    '''\n",
    "    param  -- generator object from file reader\n",
    "    return -- list of text lines\n",
    "    '''\n",
    "    body = []\n",
    "    for i, line in enumerate(mail):\n",
    "        # mail body in the third line:\n",
    "        if i == 2:\n",
    "            body.append(line)\n",
    "    return body\n",
    "\n",
    "def prepare_text_data(files_lst):\n",
    "    '''\n",
    "    param  -- list of directory to be opened\n",
    "    return -- dictionary contains index and message of every email\n",
    "    '''\n",
    "    data = {'index': [], 'msg': []}\n",
    "    for i, email in enumerate(files_lst):\n",
    "        # open every file and read the contents\n",
    "        with open(email) as mail:\n",
    "            data['index'].append(i)\n",
    "            data['msg'].append(' '.join(line.rstrip('\\n') for line in get_body(mail)))\n",
    "    return data\n",
    "\n",
    "# empty dict that will be used later for pandas\n",
    "train_data = {'index': [], 'msg': []}\n",
    "test_data  = {'index': [], 'msg': []}\n",
    "\n",
    "# get list of all emails text files from the given directory\n",
    "train_preprocessor = Preprocessing()\n",
    "test_preprocessor = Preprocessing()\n",
    "\n",
    "# training/test folder\n",
    "train_preprocessor.set_directory('train-mails/')\n",
    "test_preprocessor.set_directory('test-mails/')\n",
    "\n",
    "# now we have all email files\n",
    "train_files = train_preprocessor.get_emails()\n",
    "test_files = test_preprocessor.get_emails()\n",
    "\n",
    "# get training data and text data in form of dictionary\n",
    "train_data = prepare_text_data(train_files)\n",
    "test_data = prepare_text_data(test_files)\n",
    "\n",
    "# set training and test labels(spam vs non-spam)\n",
    "train_data['spam'] = np.zeros(train_preprocessor.get_emails_size(), dtype=int)\n",
    "test_data['spam'] = np.zeros(test_preprocessor.get_emails_size(), dtype=int)\n",
    "\n",
    "# label=1 is spam label=0 non-spam\n",
    "train_data['spam'][351:] = 1\n",
    "test_data['spam'][130:] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>msg</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>- - - - - swiss linguistic society organize su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt; deat : sun , 15 dec 91 2 : 25 : 2 est &gt; : mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>discussion s - &gt; np + np remind ago read , sou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>. . . 's much restrictive s - &gt; np np . 's \" \"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\" listserv \" international conference 1992 sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                msg  spam\n",
       "0      0  - - - - - swiss linguistic society organize su...     0\n",
       "1      1  > deat : sun , 15 dec 91 2 : 25 : 2 est > : mi...     0\n",
       "2      2  discussion s - > np + np remind ago read , sou...     0\n",
       "3      3  . . . 's much restrictive s - > np np . 's \" \"...     0\n",
       "4      4  \" listserv \" international conference 1992 sec...     0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.DataFrame.from_dict(train_data)\n",
    "test_set = pd.DataFrame.from_dict(test_data)\n",
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>msg</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>shigeru kiritanus , hajime hirose hiroya fujis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>susanne winkler focus secondary predication 19...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>johan elsness perfect preterite contemporary e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>alan c . harri , ph . d . telnos : main off : ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>la jeune equipe syntaxe anglaise et syntaxe co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                msg  spam\n",
       "0      0  shigeru kiritanus , hajime hirose hiroya fujis...     0\n",
       "1      1  susanne winkler focus secondary predication 19...     0\n",
       "2      2  johan elsness perfect preterite contemporary e...     0\n",
       "3      3  alan c . harri , ph . d . telnos : main off : ...     0\n",
       "4      4  la jeune equipe syntaxe anglaise et syntaxe co...     0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next 's nels conference jointly host harvard university mit . hop set conference date conflict major , nearby conference . host conference next fall , already set date , please send e-mail wednesday , nov . 16 . martha jo mcginni , mit\n",
      "---------------------------\n",
      "abstract due : 15 . february esslli-98 workshop current topics constraint-based theories germanic syntax august 17 - 21 , 1998 workshop hold part 10th european summer school logic , language information ( esslli-98 ) august 17 - 28 , 1998 , saarbrueken , germany * * second call papers * * organizers : tibor kiss detmar meurer ( ibm germany univ . tuebingen ) web site : http : / / www . dc . warwick . ac . uk / ~ esslli98 / workshop . html background : number approach germanic language ( exclude english ) develop constraint-base theory hpsg lfg . apart issue empirical adequacy , formal issue raise , among : - nature complex predicate mechanism formalize - linearization versus movement analysis various phenomenon - nature functional projection - configurational non-configurational property scope determination idea workshop provide forum present discuss current approach explore empirical formal issue syntax germanic language ( exclude english ) . focus germanic rather particular syntactic theory intend allow inter-framework discussion . workshop format : workshop consist five session , two 30 + 10 - minute presentation each session . submission : researcher area , especially ph . d . student young researcher , encourage submit extend abstract 2000-3000 word either hardcopy electronically ( postscript ) . accept papers available summer school reader . sufficiently many high-quality papers submit , intend publish edit volume . submission send before 15 . february 1998 one follow two organizer : tibor kiss detmar meurer ibm germany universitaet tuebingen vangerowstr . 18 seminar fuer sprachwissenschaft d-69115 heidelberg kleine wilhelmstr . 113 germany d-72074 tuebingen germany tibor @ heidelbg . ibm . com dm @ sf . nphil . uni-tuebingen . de registration : workshop contributor require register esslli-98 , eligible reduce registration fee . important dates : feb 15 , 98 : deadline submission apr 15 , 98 : notification acceptance 15 , 98 : deadline final copy aug 17 , 98 : start workshop further information : obtain further information esslli-98 please visit esslli-98 home page http : / / www . coli . uni-sb . de / essllus\n"
     ]
    }
   ],
   "source": [
    "# full text sample\n",
    "print(train_set['msg'][60])\n",
    "print('---------------------------')\n",
    "print(test_set['msg'][60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build bag of word model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'next s nels conference jointly host harvard university mit  hop set conference date conflict major  nearby conference  host conference next fall  already set date  please send email wednesday  nov  16  martha jo mcginni  mit'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    '''\n",
    "    param  -- string text to be cleaned\n",
    "    return -- filtered text without punctuations\n",
    "    '''\n",
    "    import string\n",
    "    for punc in string.punctuation:\n",
    "        text = text.replace(punc, \"\")\n",
    "    return text\n",
    "\n",
    "# apply for all rows in the dataset\n",
    "train_set['msg'] = train_set['msg'].apply(lambda row: remove_punctuation(row))\n",
    "test_set['msg'] = test_set['msg'].apply(lambda row: remove_punctuation(row))\n",
    "# here is sample after removing punctuations\n",
    "train_set['msg'][60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build bag of word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702, 3000)\n",
      "(260, 3000)\n"
     ]
    }
   ],
   "source": [
    "# import sklearn preprocessing library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# max features is 3000 words count\n",
    "count_vect = CountVectorizer(max_features=3000)\n",
    "# count all words and build matrix features from words counts\n",
    "train_count = count_vect.fit_transform(train_set['msg'])\n",
    "test_count = count_vect.fit_transform(test_set['msg'])\n",
    "# get sparse matrix\n",
    "train_features = count_vect.transform(train_set['msg']).toarray()\n",
    "test_features = count_vect.transform(test_set['msg']).toarray()\n",
    "# now we have sparse matrix in the form [n_samples, n_features]\n",
    "print(train_count.shape)\n",
    "print(test_count.shape)\n",
    "# labels\n",
    "train_labels = train_set['spam']\n",
    "test_labels = test_set['spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## it's time to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 11 119]]\n"
     ]
    }
   ],
   "source": [
    "# import SVC library\n",
    "from sklearn.svm import LinearSVC\n",
    "# initialize SVM classifier\n",
    "svm_classifier = LinearSVC()\n",
    "# fit the model to the training data\n",
    "svm_classifier.fit(train_features, train_labels)\n",
    "\n",
    "# predict the result\n",
    "result = svm_classifier.predict(test_features)\n",
    "\n",
    "# make confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_labels, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
